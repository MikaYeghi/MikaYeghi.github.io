---
layout: page
title: LangCrazyflie
description: Language-guided aerial vehicle navigation using Crazyflies.
img: assets/img/projects/LangCrazyflie/preview.jpg
importance: 1
category: fun
related_publications: false
---

## Project Description

The goal of this mini-project was to explore the application of artificial intelligence (AI) agents in controlling aerial vehicles. Specifically, I investigated how AI agents can be tasked with navigating aerial vehicles when provided with the necessary tools. While simple navigation tasks, such as "explore the left side of the room," can demonstrate basic functionality, I wanted to add complexity to make the project more engaging. Therefore, the AI agent was tasked with outlining three shapes of increasing complexity: an ellipse (easy), a heart (medium), and a Lissajous curve (hard).

## Method

For this project, I used a [Crazyflie](https://www.bitcraze.io/products/old-products/crazyflie-2-0/) drone in a Vicon motion capture environment. To implement the AI agent, I utilized [LangGraph](https://www.langchain.com/langgraph), a tool that allows the construction of AI workflows using directed graphs. The architecture of the AI agent’s graph is shown below:

<div class="row justify-content-sm-center">
    <div class="col-sm-6 mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/projects/LangCrazyflie/graph.png" title="AI agent graph architecture" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    AI agent graph in LangGraph.
</div>

The central node of the graph is the "assistant" node, which processes user queries. The "tools" node contains the set of functions required for drone navigation, including the following:
1. `navigate_drone_tool`: A tool for directing the drone’s movement.
2. `land_drone_tool`: A tool that commands the drone to land safely.
3. `get_drone_position_tool`: A tool that retrieves the drone's current position.
4. `fly_shape_tool`: A tool responsible for producing specific shapes and guiding the drone to trace those shapes.

Additionally, the "debugger" node is responsible for debugging the code generated by the shape generation tool. See the implementation code in my [GitHub repository](https://github.com/MikaYeghi/LangCrazySwarm).

## Results

See the results in the animations below.

#### Ellipse (Easy)

<div class="row justify-content-sm-center">
    <div class="col-sm mt-3 mt-md-0">
        {% include video.liquid path="assets/video/projects/LangCrazyflie/vicon_ellipse_full.mp4" class="img-fluid rounded z-depth-1" controls=true autoplay=true %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include video.liquid path="assets/video/projects/LangCrazyflie/vicon_ellipse_shape.mp4" class="img-fluid rounded z-depth-1" controls=true autoplay=true %}
    </div>
</div>
<div class="caption">
    The videos above show Vicon-captured data from a top-down view, with the camera positioned to the left. On the left, the video displays the complete trajectory flown by the drone, while the video on the right focuses on the segment of the trajectory where the drone is executing the ellipse shape.
</div>


#### Heart (Medium)

<div class="row justify-content-sm-center">
    <div class="col-sm mt-3 mt-md-0">
        {% include video.liquid path="assets/video/projects/LangCrazyflie/vicon_heart_full.mp4" class="img-fluid rounded z-depth-1" controls=true autoplay=true %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include video.liquid path="assets/video/projects/LangCrazyflie/vicon_heart_shape.mp4" class="img-fluid rounded z-depth-1" controls=true autoplay=true %}
    </div>
</div>
<div class="caption">
    The videos above show Vicon-captured data from a top-down view, with the camera positioned to the left. On the left, the video displays the complete trajectory flown by the drone, while the video on the right focuses on the segment of the trajectory where the drone is executing the heart shape.
</div>

#### Lissajous Curve (Hard)

<div class="row justify-content-sm-center">
    <div class="col-sm mt-3 mt-md-0">
        {% include video.liquid path="assets/video/projects/LangCrazyflie/vicon_lissajous_full.mp4" class="img-fluid rounded z-depth-1" controls=true autoplay=true %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include video.liquid path="assets/video/projects/LangCrazyflie/vicon_lissajous_shape.mp4" class="img-fluid rounded z-depth-1" controls=true autoplay=true %}
    </div>
</div>
<div class="caption">
    The videos above show Vicon-captured data from a top-down view, with the camera positioned to the left. On the left, the video displays the complete trajectory flown by the drone, while the video on the right focuses on the segment of the trajectory where the drone is executing the Lissajous curve.
</div>

## Conclusion

With the appropriate tools, AI agents have the potential to autonomously trace shapes that can be generated programmatically, such as those created using Python code. Additionally, alternative shape generation methods could be employed, such as mimicking a path captured by a camera. While shape tracing itself may not have immediate practical applications, it can serve as a foundational technique for more complex tasks, such as interactive drone formations. Furthermore, introducing a user-friendly interface between humans and robots opens the door for broader accessibility, allowing individuals without coding expertise to effectively utilize robotic systems.